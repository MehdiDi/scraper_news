title,url,image,category,date,content
Robot uses machine learning to harvest lettuce,https://techxplore.com/news/2019-07-robot-machine-harvest-lettuce.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/robotusesmac.jpg,Robotics,"Jul 08, 2019","A vegetable-picking robot that uses machine learning to identify and harvest a commonplace, but challenging, agricultural crop has been developed by engineers.
                                              The 'Vegebot', developed by a team at the University of Cambridge, was initially trained to recognise and harvest iceberg lettuce in a lab setting. It has now been successfully tested in a variety of field conditions in cooperation with G's Growers, a local fruit and vegetable co-operative.Although the prototype is nowhere near as fast or efficient as a human worker, it demonstrates how the use of robotics in agriculture might be expanded, even for crops like iceberg lettuce which are particularly challenging to harvest mechanically. The results are published in The Journal of Field Robotics.Crops such as potatoes and wheat have been harvested mechanically at scale for decades, but many other crops have to date resisted automation. Iceberg lettuce is one such crop. Although it is the most common type of lettuce grown in the UK, iceberg is easily damaged and grows relatively flat to the ground, presenting a challenge for robotic harvesters.""Every field is different, every lettuce is different,"" said co-author Simon Birrell from Cambridge's Department of Engineering. ""But if we can make a robotic harvester work with iceberg lettuce, we could also make it work with many other crops.""""At the moment, harvesting is the only part of the lettuce life cycle that is done manually, and it's very physically demanding,"" said co-author Julia Cai, who worked on the computer vision components of the Vegebot while she was an undergraduate student in the lab of Dr. Fumiya Iida.The Vegebot first identifies the 'target' crop within its field of vision, then determines whether a particular lettuce is healthy and ready to be harvested, and finally cuts the lettuce from the rest of the plant without crushing it so that it is 'supermarket ready'. ""For a human, the entire process takes a couple of seconds, but it's a really challenging problem for a robot,"" said co-author Josie Hughes.The Vegebot has two main components: a computer vision system and a cutting system. The overhead camera on the Vegebot takes an image of the lettuce field and first identifies all the lettuces in the image, and then for each lettuce, classifies whether it should be harvested or not. A lettuce might be rejected because it's not yet mature, or it might have a disease that could spread to other lettuces in the harvest.The researchers developed and trained a machine learning algorithm on example images of lettuces. Once the Vegebot could recognise healthy lettuces in the lab, it was then trained in the field, in a variety of weather conditions, on thousands of real lettuces.A second camera on the Vegebot is positioned near the cutting blade, and helps ensure a smooth cut. The researchers were also able to adjust the pressure in the robot's gripping arm so that it held the lettuce firmly enough not to drop it, but not so firm as to crush it. The force of the grip can be adjusted for other crops.""We wanted to develop approaches that weren't necessarily specific to iceberg lettuce, so that they can be used for other types of above-ground crops,"" said Iida, who leads the team behind the research.In future, robotic harvesters could help address problems with labour shortages in agriculture, and could also help reduce food waste. At the moment, each field is typically harvested once, and any unripe vegetables or fruits are discarded. However, a robotic harvester could be trained to pick only ripe vegetables, and since it could harvest around the clock, it could perform multiple passes on the same field, returning at a later date to harvest the vegetables that were unripe during previous passes.""We're also collecting lots of data about lettuce, which could be used to improve efficiency, such as which fields have the highest yields,"" said Hughes. ""We've still got to speed our Vegebot up to the point where it could compete with a human, but we think robots have lots of potential in agri-tech.""
                                                                                                                        "
Flying blind: Apps help visually impaired navigate airport,https://techxplore.com/news/2019-07-apps-visually-impaired-airport.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/6-flyingblinda.jpg,Software,"Jul 08, 2019","Navigating airports can be tricky. They're loud, crowded and not always laid out intuitively. They're even more challenging for visually impaired people.
                                              Chieko Asakawa knows those challenges firsthand, and she has also devised a remedy.Asakawa has been blind since she was 14 and is now an IBM Fellow and a professor in Carnegie Mellon University's Robotics Institute. This spring, she and other researchers at Carnegie Mellon launched a navigation app for Pittsburgh International Airport that provides turn-by-turn audio instructions to users on how to get to their destination, be it a departure gate, restaurant or restroom.Pittsburgh is one of a growing number of airports around the globe to provide wayfinding apps. The Pittsburgh app, called NavCog, was first used at the Carnegie Mellon campus and works almost like an indoor GPS.""Independence is very important,"" she said. ""Technology has been helping us to be more independent and this is one of the examples. We still have a lot of challenges, but we will keep working to make it easier.""Typically, visually impaired travelers arrive at the Pittsburgh airport and request an escort, Asakawa said, but escorts aren't available until passengers check in. So they must reach the counter on their own.The escort brings passengers to their gate and leaves, she said. For Asakawa, if she wanted a coffee, or if the flight was delayed, it was very difficult to manage, and very often she'd just be stranded at the gate.With NavCog, she can get up and find the gift shop or coffee shop or even just wander around a bit, she said. The app is up and running and free to download.It works with the help of hundreds of Bluetooth beacons installed inside the airport to wirelessly communicate a user's location.Users put in where they are going; for example, Gate A3. The app gives users audio instructions like ""walk 20 feet and turn left"" and gets them to their destination. The app lets users know what stores they might be passing, giving them a better sense of their surroundings, and shopping options.It relies on a map of the terminal that has been annotated with the locations of restrooms, restaurants, gates, entrances and ticketing counters.Ten legally blind people tested the app using an iPhone 8, traversing the terminal's large open spaces, escalators and moving walkways with few errors. Most users were able to reach the ticketing counter in three minutes, traverse the terminal in about six minutes, go from the gate to a restroom in a minute and go from the gate to a restaurant in about four minutes, the researchers said.Carnegie Mellon and the airport have partnered in developing new systems and technologies for enhancing traveler experiences and airport operations. The technology is tested at the university's on-site lab at the airport.""Part of our commitment to the public includes making sure our airport works for everyone, particularly as we modernize our facility for the future,"" said airport CEO Christina Cassotis.The city is building a new airport terminal, slated to open in 2023, and incorporating the latest technology is a top priority, she said.Dozens of airports, including Philadelphia International, offer free use of a service called Aira, where users connect with an ""agent"" either by using glasses equipped with a camera or through a smartphone app that accesses the user's camera.Agents look at the footage and help relay what they see to the user, getting them where they need to go. The service is typically subscription-based and can be used at home or at work, but participating airports pay the fees for users on site.Louisville International in Kentucky installed an app similar to NavCog in 2017, created by the American Printing House for the Blind, a company that develops products for the visually impaired.Brian Charlson, with the American Council of the Blind, has been involved in wayfinding for over 30 years and has seen a number of airports and train stations try different technological approaches to make their spaces easier to navigate for the visually impaired. The NavCog app, he said, is a useful mashup of systems he's seen over the years.He cautions, though, that the blind population is older and has a high unemployment rate, so many don't have access to smartphones, meaning such apps might be inaccessible.Having options is always beneficial for the visually impaired, said John McInerney, interim CEO of the Pennsylvania Association for the Blind.""The apps can be very helpful,"" McInerney said. ""The whole idea is that you would not have to depend on a person to help you. But even today, that's still a pretty good option.""
                                                                                                                        "
Jumping space robot 'flies' like a spacecraft,https://techxplore.com/news/2019-07-space-robot-flies-spacecraft.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/jumpingspace.gif,Robotics,"Jul 08, 2019","Astronauts on the Moon found themselves hopping around, rather than simply walking. Switzerland's SpaceBok planetary exploration robot has followed their example, launching all four legs off the ground during tests at ESA's technical heart.
                                              SpaceBok is a quadruped robot designed and built by a Swiss student team from ETH Zurich and ZHAW Zurich. It is currently being tested using robotic facilities at ESA's ESTEC technical centre in the Netherlands.Work is proceeding under the leadership of Ph.D. student Hendrik Kolvenbach from ETH Zurich's Robotic Systems Lab, currently based at ESTEC. The robot is being used to investigate the potential of ""dynamic walking"" to get around in low gravity environments.Hendrik explains: ""Instead of static walking, where at least three legs stay on the ground at all times, dynamic walking allows for gaits with full flight phases during which all legs stay off the ground. Animals make use of dynamic gaits due to their efficiency, but until recently, the computational power and algorithms required for control made it challenging to realize them on robots.""For the lower gravity environments of the Moon, Mars or asteroids, jumping off the ground like this turns out to be a very efficient way to get around.""""Astronauts moving in the one-sixth gravity of the Moon adopted jumping instinctively. SpaceBok could potentially go up to 2 m high in lunar gravity, although such a height poses new challenges. Once it comes off the ground the legged robot needs to stabilize itself to come down again safely—it's basically behaving like a mini-spacecraft at this point,"" says team member Alexander Dietsche.""So what we've done is harness one of the methods a conventional satellite uses to control its orientation, called a reaction wheel. It can be accelerated and decelerated to trigger an equal and opposite reaction in SpaceBok itself,"" explains team member Philip Arm.""Additionally, SpaceBok's legs incorporate springs to store energy during landing and release it at take-off, significantly reducing the energy needed to achieve those jumps,"" adds another team member, Benjamin Sun.The team is slowly increasing the height of the robot's repetitive jumps, up to 1.3 meters in simulated lunar gravity conditions so far.Test rigs have been set up to simulate various gravity environments, mimicking not only lunar conditions but also the very low gravities of asteroids. The lower the gravity the longer the flight phase can be for each robot jump, but effective control is needed for both take-off and landing.SpaceBok was placed on its side, then attached to a free-floating platform to reproduce zero-G conditions in two dimensions. When jumping off a wall its reaction wheel allowed it to twirl around mid-jump, letting it land feet first again on the other side of the chamber—as if it was jumping along a scaled-down single low-gravity surface.Hendrik added: ""The testing went sufficiently well that we even used SpaceBok to play a live-action game of Pong, the video game classic.""Testing will continue in more realistic conditions, with jumps made over obstacles, hilly terrain, and realistic soil, eventually moving out of doors.Hendrik is studying at ESTEC through ESA's Networking Partnering Initiative, intended to harness advanced academic research for space applications.
                                                                                                                        "
Bitcoin compared to what? New index shows energy consumption,https://techxplore.com/news/2019-07-bitcoin-index-energy-consumption.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2018/1-bitcoin.jpg,Energy & Green Tech,"Jul 08, 2019","Bitcoin has landed front and center in the ongoing debate over benefits of cryptocurrencies and impact on the environment.
                                              Numerous headlines this month carry stark comparisons and to distill them all: ""Bitcoin uses about as much energy as Switzerland.""Bitcoin is using around seven gigawatts of electricity, equal to 0.21% of the world's supply, according to an online tool's estimate, said BBC News. ""That is as much power as would be generated by seven Dungeness nuclear power plants at once,"" said  Chris Baraniuk, BBC News.""That's a bit more than the entire country of Switzerland is using,"" said Naked Security, citing that online tool, which is the Cambridge Bitcoin Electricity Consumption Index (CBECI) (Switzerland, 58.46 TWh per year;  Bitcoin, 58.93 TWh per year).The Cambridge Center for Alternative Finance at Cambridge Judge Business School, University of Cambridge, launched the index. What is its purpose? It  provides a real-time estimate of the total annual electricity usage of the Bitcoin network and enables live comparisons to put the numbers in perspective.As Baraniuk explained, ""the miners are more or less constantly working. The University of Cambridge tool models the economic lifetime of the world's Bitcoin miners. It uses an average electricity price per kilowatt hour ($0.05, £0.04) and the energy demands of the Bitcoin network.""Once you can free your mind off the Switzerland perspective, here are some other comparisons delivered by the CBECI website: the current annual estimate of 50 terawatt-hours (TWh) could power all European tea kettles used to boil water for a year, or satisfy the energy needs of the University of Cambridge for 365 years.""The tool makes it easier to see how the crypto-currency network's energy usage compares with other entities,"" said Baraniuk.The index does not veer from a mission to literally put things in perspective. Looked at from a different view, ""the electricity wasted each year by always-on but inactive home devices in the United States alone could power the Bitcoin network more than four times.""CBECI wants to be a step toward a more comprehensive analysis of the environmental footprint of the cryptocurrency mining industry overall. Future plans are for an interactive geographical map of mining facilities globally. That map will provide a more accurate assessment of Bitcoin's total carbon emissions.For those who are not yet familiar with Bitcoin (beyond hearing how popular it is as a cryptocurrency) many sites offer definitions and backgrounds. To understand why it is being tracked, JD Alois in Crowdfund Insider  had a helpful discussion. ""Over time, the mining process has migrated away from hobbyists operating their own mining nodes to highly professional mining farms scattered around the world competing to earn free money; except the virtual currency is not really free as it costs considerable sums to operate these farms—most of it in electricity bills.""Bitcoin mining relies on computation-heavy cryptographic operations, said the CBECI site, that require significant amounts of electricity.As a result, ""Bitcoin, and those individuals and corporations that mine the crypto, have come under scrutiny and criticism for the amount of energy used in creating the crypto."" As for the CBECI, Crowdfund Insider called it ""probably the best real-time estimate of Bitcoin mining energy usage in existence.""Bitcoin basics from the University of Cambridge:  Bitcoin has its own, native cryptocurrency called bitcoin (BTC)...New bitcoins are issued, according to a transparent and predictable schedule, on average every 10 minutes through a process called mining... one bitcoin can be divided out to eight decimal places. This means that one bitcoin corresponds to 100 million satoshi, the smallest base unit.As interesting as the CBECI launch news is, no less significant chatter resides in an article that was published in Joule. In ""The Carbon Footprint of Bitcoin,"" the authors stated that ""Participation in the Bitcoin blockchain validation process requires specialized hardware and vast amounts of electricity, which translates into a significant carbon footprint.""As of November last year, in a determination by the authors of the annual electricity consumption of Bitcoin, the number turned out  to be 45.8 TWh with an estimated annual carbon emissions range from 22.0 to 22.9 MtCO2. ""This means that the emissions produced by Bitcoin sit between the levels produced by the nations of Jordan and Sri Lanka, which is comparable to the level of Kansas City."" The authors acknowledged that ""cryptocurrencies cause a relatively small fraction of global emissions,"" but, they added, ""regulating this largely gambling-driven source of carbon emissions appears to be a simple means to contribute to decarbonizing the economy.""Alan Martin, The Inquirer, agreed with the view that the percentage is small but still deserving recognition. He wrote that although the current estimate from the site was such a small percent  of the world's entire electricity consumption, it still was ""an alarming total for a currency that isn't widely accepted.""Does anyone attach a proposed solution for the future of Bitcoin vis a vis the environment? In April, Yale Environment Review carried an article by Brurce Mecca. ""Despite its considerable potential benefits, Bitcoin mining is designed to be energy intensive. Even the verification process needed to trade Bitcoin is a polluting endeavor.""The author examined options for policy measures with final conclusions, saying that ""the lack of collective international response to regulate Bitcoin is at the root of the problem. Ultimately, stronger international cooperation will be necessary to 'green' Blockchain and digital currencies.""
                                                                                                                        "
Robots step up to ace those big bad cinder blocks,https://techxplore.com/news/2019-07-robots-ace-big-bad-cinder.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/5d21e64598a00.jpg,Robotics,"Jul 07, 2019","Well, each to his own taste. Kittens making friends with balls of yarn are absolute magnets for video surfers but a rival army of video clicksters can never max out staring at humanoids navigating where they want to go.
                                              The latest video showcasing humanoid robots on the move is impressing viewers with the deft and successful way they are navigating a cinder block maze.The video on the latter is IHMC, the Institute for Human and Machine Cognition (IHMC). ""To walk through a cluttered and complicated environment,"" said the team, legged robots need to figure out where they can put their feet. Added challenge: This needs to be done quickly, whether the terrain is flat or complex. IHMC's autonomous footstep planning program is at work on both Boston Dynamics' robot, and NASA-developed Valkyrie.The team used the two robots, the Atlas (Boston Dynamics) and the Valkyrie (NASA Johnson Space Center) for the most recent showcase. Another key feature was its 'head.'""The method uses the machines' sensors to work out the most efficient path to a human-selected location,"" said TNW.""In this video,"" the narrator said, ""we use the Carnegie Robotics MultiSense SL head to generate point cloud of the environment. By segmenting this point cloud into planar regions, we represent the huge amount of data coming from the perception sensors in a much more compact form."" They further decomposed these planar regions into a collection-of polygons. Engadget: ""Each section is then interpreted into a series of polygons to create a model of the environment, so the robot can plan out each of its steps to get from its starting point to its goal.""The IHMC team, during the DARPA challenge, had previously used the Atlas robot. An operator directed Atlas. Footsteps were placed in the interface. The process was slow and placed a burden on the operator. Another downside was that their placing individual footsteps was error-prone. Atlas fell down on the first day of the finals competition.This time around, to circumvent human error, the new system let an operator select the desired location, said TNW, ""but ultimately relies on an algorithm to figure out how to get the robot there and avoid obstacles.""""Basically, IHMC manages these complex navigation operations by specifying a beginning and end point for the robot,"" said Darrell Etherington in TechCrunch, ""and then mapping all possible paths on a footstep-by-footstep basis, evaluating the cost of each and ultimately arriving at a best possible path—all of which can occur relatively quickly on modern hardware.""In one video scene of testing it shows the team having the robot walk across a set of cinder blocks, where there are only a few footholds that are possible. They can also plan paths where the robot has no choice but to only use partial footholds.Currently, they said in their video notes, narrow terrain has a success rate of about 50 percent, rough terrain is about 90 percent, whereas flat ground is near 100 percent.Pittsburgh, Pennsylvania based Carnegie Robotics, meanwhile, is a provider of advanced robotics sensors and platforms. The original MultiSense SL had been a sensor of choice for Atlas humanoid robots in the DARPA Robotics Challenge (DRC). As the humanoid head, the SL provided the majority of perceptual data used for teleoperation as well as automated control. What's next?""We plan on increasing planner speed and the ability to plan through mazes and to unseen goals,"" they said in the video notes. It' s clear that the team is continuing attempts to conquer bipedal walking. IHMC team stated as much.""Our humanoid projects are focused on pushing our bipedal humanoids capabilities forward to handle rough terrain without any knowledge of the environment from onboard sensors...We are also focusing on the ability to robustly handle external disturbances. Our goal is to tackle increasingly more difficult walking challenges.""The video and paper were submitted to Humanoids 2019 - International Conference on Humanoid Robots event to take place later this year.
                                                                                                                        "
