title,url,image,category,date,content
Robot uses machine learning to harvest lettuce,https://techxplore.com/news/2019-07-robot-machine-harvest-lettuce.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/robotusesmac.jpg,Robotics,"Jul 08, 2019","A vegetable-picking robot that uses machine learning to identify and harvest a commonplace, but challenging, agricultural crop has been developed by engineers.
                                              The 'Vegebot', developed by a team at the University of Cambridge, was initially trained to recognise and harvest iceberg lettuce in a lab setting. It has now been successfully tested in a variety of field conditions in cooperation with G's Growers, a local fruit and vegetable co-operative.Although the prototype is nowhere near as fast or efficient as a human worker, it demonstrates how the use of robotics in agriculture might be expanded, even for crops like iceberg lettuce which are particularly challenging to harvest mechanically. The results are published in The Journal of Field Robotics.Crops such as potatoes and wheat have been harvested mechanically at scale for decades, but many other crops have to date resisted automation. Iceberg lettuce is one such crop. Although it is the most common type of lettuce grown in the UK, iceberg is easily damaged and grows relatively flat to the ground, presenting a challenge for robotic harvesters.""Every field is different, every lettuce is different,"" said co-author Simon Birrell from Cambridge's Department of Engineering. ""But if we can make a robotic harvester work with iceberg lettuce, we could also make it work with many other crops.""""At the moment, harvesting is the only part of the lettuce life cycle that is done manually, and it's very physically demanding,"" said co-author Julia Cai, who worked on the computer vision components of the Vegebot while she was an undergraduate student in the lab of Dr. Fumiya Iida.The Vegebot first identifies the 'target' crop within its field of vision, then determines whether a particular lettuce is healthy and ready to be harvested, and finally cuts the lettuce from the rest of the plant without crushing it so that it is 'supermarket ready'. ""For a human, the entire process takes a couple of seconds, but it's a really challenging problem for a robot,"" said co-author Josie Hughes.The Vegebot has two main components: a computer vision system and a cutting system. The overhead camera on the Vegebot takes an image of the lettuce field and first identifies all the lettuces in the image, and then for each lettuce, classifies whether it should be harvested or not. A lettuce might be rejected because it's not yet mature, or it might have a disease that could spread to other lettuces in the harvest.The researchers developed and trained a machine learning algorithm on example images of lettuces. Once the Vegebot could recognise healthy lettuces in the lab, it was then trained in the field, in a variety of weather conditions, on thousands of real lettuces.A second camera on the Vegebot is positioned near the cutting blade, and helps ensure a smooth cut. The researchers were also able to adjust the pressure in the robot's gripping arm so that it held the lettuce firmly enough not to drop it, but not so firm as to crush it. The force of the grip can be adjusted for other crops.""We wanted to develop approaches that weren't necessarily specific to iceberg lettuce, so that they can be used for other types of above-ground crops,"" said Iida, who leads the team behind the research.In future, robotic harvesters could help address problems with labour shortages in agriculture, and could also help reduce food waste. At the moment, each field is typically harvested once, and any unripe vegetables or fruits are discarded. However, a robotic harvester could be trained to pick only ripe vegetables, and since it could harvest around the clock, it could perform multiple passes on the same field, returning at a later date to harvest the vegetables that were unripe during previous passes.""We're also collecting lots of data about lettuce, which could be used to improve efficiency, such as which fields have the highest yields,"" said Hughes. ""We've still got to speed our Vegebot up to the point where it could compete with a human, but we think robots have lots of potential in agri-tech.""
                                                                                                                        "
Jumping space robot 'flies' like a spacecraft,https://techxplore.com/news/2019-07-space-robot-flies-spacecraft.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/jumpingspace.gif,Robotics,"Jul 08, 2019","Astronauts on the Moon found themselves hopping around, rather than simply walking. Switzerland's SpaceBok planetary exploration robot has followed their example, launching all four legs off the ground during tests at ESA's technical heart.
                                              SpaceBok is a quadruped robot designed and built by a Swiss student team from ETH Zurich and ZHAW Zurich. It is currently being tested using robotic facilities at ESA's ESTEC technical centre in the Netherlands.Work is proceeding under the leadership of Ph.D. student Hendrik Kolvenbach from ETH Zurich's Robotic Systems Lab, currently based at ESTEC. The robot is being used to investigate the potential of ""dynamic walking"" to get around in low gravity environments.Hendrik explains: ""Instead of static walking, where at least three legs stay on the ground at all times, dynamic walking allows for gaits with full flight phases during which all legs stay off the ground. Animals make use of dynamic gaits due to their efficiency, but until recently, the computational power and algorithms required for control made it challenging to realize them on robots.""For the lower gravity environments of the Moon, Mars or asteroids, jumping off the ground like this turns out to be a very efficient way to get around.""""Astronauts moving in the one-sixth gravity of the Moon adopted jumping instinctively. SpaceBok could potentially go up to 2 m high in lunar gravity, although such a height poses new challenges. Once it comes off the ground the legged robot needs to stabilize itself to come down again safely—it's basically behaving like a mini-spacecraft at this point,"" says team member Alexander Dietsche.""So what we've done is harness one of the methods a conventional satellite uses to control its orientation, called a reaction wheel. It can be accelerated and decelerated to trigger an equal and opposite reaction in SpaceBok itself,"" explains team member Philip Arm.""Additionally, SpaceBok's legs incorporate springs to store energy during landing and release it at take-off, significantly reducing the energy needed to achieve those jumps,"" adds another team member, Benjamin Sun.The team is slowly increasing the height of the robot's repetitive jumps, up to 1.3 meters in simulated lunar gravity conditions so far.Test rigs have been set up to simulate various gravity environments, mimicking not only lunar conditions but also the very low gravities of asteroids. The lower the gravity the longer the flight phase can be for each robot jump, but effective control is needed for both take-off and landing.SpaceBok was placed on its side, then attached to a free-floating platform to reproduce zero-G conditions in two dimensions. When jumping off a wall its reaction wheel allowed it to twirl around mid-jump, letting it land feet first again on the other side of the chamber—as if it was jumping along a scaled-down single low-gravity surface.Hendrik added: ""The testing went sufficiently well that we even used SpaceBok to play a live-action game of Pong, the video game classic.""Testing will continue in more realistic conditions, with jumps made over obstacles, hilly terrain, and realistic soil, eventually moving out of doors.Hendrik is studying at ESTEC through ESA's Networking Partnering Initiative, intended to harness advanced academic research for space applications.
                                                                                                                        "
Bitcoin compared to what? New index shows energy consumption,https://techxplore.com/news/2019-07-bitcoin-index-energy-consumption.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2018/1-bitcoin.jpg,Energy & Green Tech,"Jul 08, 2019","Bitcoin has landed front and center in the ongoing debate over benefits of cryptocurrencies and impact on the environment.
                                              Numerous headlines this month carry stark comparisons and to distill them all: ""Bitcoin uses about as much energy as Switzerland.""Bitcoin is using around seven gigawatts of electricity, equal to 0.21% of the world's supply, according to an online tool's estimate, said BBC News. ""That is as much power as would be generated by seven Dungeness nuclear power plants at once,"" said  Chris Baraniuk, BBC News.""That's a bit more than the entire country of Switzerland is using,"" said Naked Security, citing that online tool, which is the Cambridge Bitcoin Electricity Consumption Index (CBECI) (Switzerland, 58.46 TWh per year;  Bitcoin, 58.93 TWh per year).The Cambridge Center for Alternative Finance at Cambridge Judge Business School, University of Cambridge, launched the index. What is its purpose? It  provides a real-time estimate of the total annual electricity usage of the Bitcoin network and enables live comparisons to put the numbers in perspective.As Baraniuk explained, ""the miners are more or less constantly working. The University of Cambridge tool models the economic lifetime of the world's Bitcoin miners. It uses an average electricity price per kilowatt hour ($0.05, £0.04) and the energy demands of the Bitcoin network.""Once you can free your mind off the Switzerland perspective, here are some other comparisons delivered by the CBECI website: the current annual estimate of 50 terawatt-hours (TWh) could power all European tea kettles used to boil water for a year, or satisfy the energy needs of the University of Cambridge for 365 years.""The tool makes it easier to see how the crypto-currency network's energy usage compares with other entities,"" said Baraniuk.The index does not veer from a mission to literally put things in perspective. Looked at from a different view, ""the electricity wasted each year by always-on but inactive home devices in the United States alone could power the Bitcoin network more than four times.""CBECI wants to be a step toward a more comprehensive analysis of the environmental footprint of the cryptocurrency mining industry overall. Future plans are for an interactive geographical map of mining facilities globally. That map will provide a more accurate assessment of Bitcoin's total carbon emissions.For those who are not yet familiar with Bitcoin (beyond hearing how popular it is as a cryptocurrency) many sites offer definitions and backgrounds. To understand why it is being tracked, JD Alois in Crowdfund Insider  had a helpful discussion. ""Over time, the mining process has migrated away from hobbyists operating their own mining nodes to highly professional mining farms scattered around the world competing to earn free money; except the virtual currency is not really free as it costs considerable sums to operate these farms—most of it in electricity bills.""Bitcoin mining relies on computation-heavy cryptographic operations, said the CBECI site, that require significant amounts of electricity.As a result, ""Bitcoin, and those individuals and corporations that mine the crypto, have come under scrutiny and criticism for the amount of energy used in creating the crypto."" As for the CBECI, Crowdfund Insider called it ""probably the best real-time estimate of Bitcoin mining energy usage in existence.""Bitcoin basics from the University of Cambridge:  Bitcoin has its own, native cryptocurrency called bitcoin (BTC)...New bitcoins are issued, according to a transparent and predictable schedule, on average every 10 minutes through a process called mining... one bitcoin can be divided out to eight decimal places. This means that one bitcoin corresponds to 100 million satoshi, the smallest base unit.As interesting as the CBECI launch news is, no less significant chatter resides in an article that was published in Joule. In ""The Carbon Footprint of Bitcoin,"" the authors stated that ""Participation in the Bitcoin blockchain validation process requires specialized hardware and vast amounts of electricity, which translates into a significant carbon footprint.""As of November last year, in a determination by the authors of the annual electricity consumption of Bitcoin, the number turned out  to be 45.8 TWh with an estimated annual carbon emissions range from 22.0 to 22.9 MtCO2. ""This means that the emissions produced by Bitcoin sit between the levels produced by the nations of Jordan and Sri Lanka, which is comparable to the level of Kansas City."" The authors acknowledged that ""cryptocurrencies cause a relatively small fraction of global emissions,"" but, they added, ""regulating this largely gambling-driven source of carbon emissions appears to be a simple means to contribute to decarbonizing the economy.""Alan Martin, The Inquirer, agreed with the view that the percentage is small but still deserving recognition. He wrote that although the current estimate from the site was such a small percent  of the world's entire electricity consumption, it still was ""an alarming total for a currency that isn't widely accepted.""Does anyone attach a proposed solution for the future of Bitcoin vis a vis the environment? In April, Yale Environment Review carried an article by Brurce Mecca. ""Despite its considerable potential benefits, Bitcoin mining is designed to be energy intensive. Even the verification process needed to trade Bitcoin is a polluting endeavor.""The author examined options for policy measures with final conclusions, saying that ""the lack of collective international response to regulate Bitcoin is at the root of the problem. Ultimately, stronger international cooperation will be necessary to 'green' Blockchain and digital currencies.""
                                                                                                                        "
Robots step up to ace those big bad cinder blocks,https://techxplore.com/news/2019-07-robots-ace-big-bad-cinder.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/5d21e64598a00.jpg,Robotics,"Jul 07, 2019","Well, each to his own taste. Kittens making friends with balls of yarn are absolute magnets for video surfers but a rival army of video clicksters can never max out staring at humanoids navigating where they want to go.
                                              The latest video showcasing humanoid robots on the move is impressing viewers with the deft and successful way they are navigating a cinder block maze.The video on the latter is IHMC, the Institute for Human and Machine Cognition (IHMC). ""To walk through a cluttered and complicated environment,"" said the team, legged robots need to figure out where they can put their feet. Added challenge: This needs to be done quickly, whether the terrain is flat or complex. IHMC's autonomous footstep planning program is at work on both Boston Dynamics' robot, and NASA-developed Valkyrie.The team used the two robots, the Atlas (Boston Dynamics) and the Valkyrie (NASA Johnson Space Center) for the most recent showcase. Another key feature was its 'head.'""The method uses the machines' sensors to work out the most efficient path to a human-selected location,"" said TNW.""In this video,"" the narrator said, ""we use the Carnegie Robotics MultiSense SL head to generate point cloud of the environment. By segmenting this point cloud into planar regions, we represent the huge amount of data coming from the perception sensors in a much more compact form."" They further decomposed these planar regions into a collection-of polygons. Engadget: ""Each section is then interpreted into a series of polygons to create a model of the environment, so the robot can plan out each of its steps to get from its starting point to its goal.""The IHMC team, during the DARPA challenge, had previously used the Atlas robot. An operator directed Atlas. Footsteps were placed in the interface. The process was slow and placed a burden on the operator. Another downside was that their placing individual footsteps was error-prone. Atlas fell down on the first day of the finals competition.This time around, to circumvent human error, the new system let an operator select the desired location, said TNW, ""but ultimately relies on an algorithm to figure out how to get the robot there and avoid obstacles.""""Basically, IHMC manages these complex navigation operations by specifying a beginning and end point for the robot,"" said Darrell Etherington in TechCrunch, ""and then mapping all possible paths on a footstep-by-footstep basis, evaluating the cost of each and ultimately arriving at a best possible path—all of which can occur relatively quickly on modern hardware.""In one video scene of testing it shows the team having the robot walk across a set of cinder blocks, where there are only a few footholds that are possible. They can also plan paths where the robot has no choice but to only use partial footholds.Currently, they said in their video notes, narrow terrain has a success rate of about 50 percent, rough terrain is about 90 percent, whereas flat ground is near 100 percent.Pittsburgh, Pennsylvania based Carnegie Robotics, meanwhile, is a provider of advanced robotics sensors and platforms. The original MultiSense SL had been a sensor of choice for Atlas humanoid robots in the DARPA Robotics Challenge (DRC). As the humanoid head, the SL provided the majority of perceptual data used for teleoperation as well as automated control. What's next?""We plan on increasing planner speed and the ability to plan through mazes and to unseen goals,"" they said in the video notes. It' s clear that the team is continuing attempts to conquer bipedal walking. IHMC team stated as much.""Our humanoid projects are focused on pushing our bipedal humanoids capabilities forward to handle rough terrain without any knowledge of the environment from onboard sensors...We are also focusing on the ability to robustly handle external disturbances. Our goal is to tackle increasingly more difficult walking challenges.""The video and paper were submitted to Humanoids 2019 - International Conference on Humanoid Robots event to take place later this year.
                                                                                                                        "
Toyota to test solar panels for electric cars,https://techxplore.com/news/2019-07-toyota-solar-panels-electric-cars.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/5d2070a896c95.jpg,Energy & Green Tech,"Jul 06, 2019","What's not to like about this concept: high-efficiency solar cells gifting electric cars with mileage.
                                              Bertel Schmitt, The Drive, said, ""The solar roof could morph from mostly a marketing-device to a helpful feature."" He noted that,  referring to plug-ins, ""On a fair-weather day, the juice would be provided by the sun, a big improvement especially for people who don't have their own garage.""Toyota has ambitions over the concept and is to start testing an onboard solar recharging system where the hood, the roof, and back are covered with cells. The solar roof can charge while the car is on the move.It did not escape Interesting Engineering's notice that the new solar battery cell can fit a larger surface. ""The solar battery cell is a thin film about 0.03 mm thick. Because it is so thin, it can fit the curves of the vehicle including the roof, hood                 , and rear hatch door,"" said the report. Darrell Etherington, TechCrunch, said at center stage was the new and improved version of the solar power cells previously launched on the Japan-exclusive Prius PHV.The Toyota news release said ""the demo car employs a system that charges the driving battery while the vehicle is parked and also while it's being driven."" This was seen as an interesting development expected to lead to improvements in the electric car's cruising range and fuel efficiency.""Previously, the Prius PHV charged the driving battery only while the vehicle was parked. However, with improvements in power generation output, the demo car employs a system that charges while the vehicle is being driven. This is expected to boost the BEV-mode cruising range and fuel efficiency significantly,"" said Toyota.NEDO, which is a national research and development organization, Sharp and Toyota are to start some road trials where the electric cars will be equipped with solar batteries. NEDO and Sharp will share a selection of trial data results, said Toyota. Those presiding over the tests are going to see the power generation output of the solar panel. Toyota City, Aichi Prefecture, Tokyo, and other areas are the sites planned for the test, where weather and driving conditions will vary.Etherington commented that the car's prototype cells being able to convert solar energy at 34 percent and up was better than the existing commercial version's numbers.Reports noted the solar cells were extremely efficient. According to The Drive, the solar Sharp-made solar cells are of the triple-junction compound type, sporting a conversion efficiency of 34 percent, and occasionally more. Etherington: ""The new system will provide up to 44.5 km (27.7 miles) of additional range per day while parked and soaking up sun, and can add up to 56.3 km (35 miles) of power to both the driving system and the auxiliary power battery on board, which runs the AC, navigation and more.""All in all, Elektrek offered its take on the news:""As we always like to point out with these solar car efforts, a car's roof is not the most ideal place to install solar cells. They would most likely be more efficient installed on the rooftop of a home and then, you can use the power to charge your vehicle. However, there's something appealing about your vehicle producing its own energy and it is starting to get more attractive with the specs Toyota is talking about now.""
                                                                                                                        "
Companies spell out guiding principles for autonomous cars to be safe,https://techxplore.com/news/2019-07-companies-principles-autonomous-cars-safe.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/companiesspe.jpg,Automotive,"Jul 05, 2019","""Safety First for Automated Driving"" has been compiled by 11 authors representing automotive and mobility industry thought leadership.
                                              This work is not a literature review. It's not a milestones report of yesterday and tomorrow. While there is no shortage of publications on the topic of self-driving cars, the authors carry their own mission: It's a framework for safety in automated passenger vehicles, where industry players are looking closely and carefully at safety by design.What is still missing from existing literature, they stated, is verification and validation of such systems. While the authors represent different companies, they share a goal of ""industry-wide standardization of automated driving."" Their intended audience? That would include regulators, automated-driving industry players, insurance companies and—not leaving anyone out—""any persons involved in later standardization efforts.""Intel was among the companies represented in the list of authors. ""We are proud to have contributed to the groundbreaking work to establish a framework for introducing automated vehicles that are safe by design,"" said Intel's Jack Weast, senior principal engineer. The document, while addressing the technical, was clearly written and often stated sobering analyses of where the industry is in safe self-driving systems. At the heart of the document are 12 principles that all self-driving vehicles should adhere to moving forward. ""Existing standards do not present solutions to some of the most problematic topics of automated driving systems,"" said the authors, ""such as the safety assurance of artificial intelligence (the most relevant algorithms derive from the fields of machine learning and neural networks, see Appendix B), human factors and psychology, and the technological capability of the sensory devices used as inputs to the automated driving system.""To be sure, it is safe to say that no discussion of potential guidelines for safety would be complete without reference to the deep neural networks used for automated driving systems.""Machine learning...is seen as a crucial technology for automated driving systems,"" they wrote. ""Consequently, the development process for machine learning algorithms responsible for executing safety-related tasks of automated driving systems must undergo strict assessment.""Another topic for highlighting has to do with cybersecurity. We get a lot of information about hijacked computers but what about addressing risks of highjacking fleets of cars? ""The automotive industry is facing new challenges in automated driving due to the extreme connectivity within automated driving vehicles and between those vehicles and their operating environment."" They said the challenges included ensuring safety to protecting fleets and customers from cybersecurity attacks.""Connectivity additions include new interfaces between the control functions of connected vehicles, IT backend systems, and other external information sources,"" they wrote. ""This rich attack surface creates considerable interest for malicious actors with various goals...Most importantly, cybersecurity principles and practices should be applied to ensure that attackers cannot gain arbitrary control of a vehicle's movement and that attacks are exceptionally difficult to scale to the point of simultaneously exploiting multiple vehicles.""In reading the document, TechSpot cut to the chase, asking, ""Is the industry attempting to regulate itself?"" Cohen Coberly in TechSpot recognized that the document was talking about that delicate balance of driver responsibility and system responsibility in self-driving automobile safety.He wrote that ""these principles aim to blend user and vehicle responsibility, ensuring that a driver knows what's expected of them at all times—for example, explicitly informing them when a manual take-over is necessary—while preventing the vehicle's autonomous systems from putting drivers in harm's way in the first place.""It is not certain how many car makers will adopt the 12 principles laid out in the paper but Coberly commented that ""given the many controversies that have surrounded self-driving cars over the past couple of years, self-regulation like this will probably seem preferable to government intervention.""Sasha Lekach, Mashable, delivered a description of what subjects are covered by the 12 guiding principles: safe operation; operational design domain; vehicle operator-initiated handover; security; user responsibility; vehicle-initiated handover; interdependency between the vehicle operator and the automated system; safety assessment; data recording; passive safety; behavior in traffic; and a safety layer.
                                                                                                                        "
How the Avengers assemble: Ecology-based metrics model effective cast sizes for Marvel movies,https://techxplore.com/news/2019-07-avengers-ecology-based-metrics-effective-sizes.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/usingecology.jpg,Computer Sciences,"Jul 05, 2019","In a recent study, researchers at the ARC Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS) in Adelaide have tried to use ecology-related concepts to model effective cast sizes for movies, focusing on characters from the Marvel Cinematic Universe (MCU). Their research, outlined in a paper pre-published on arXiv, gathered interesting findings that could shed light on some factors associated with the success of Marvel movies.
                                              ""We're huge fans of the recent suite of Marvel movies, the Marvel Cinematic Universe, as it's called,"" Matthew Roughan, one of the researchers who carried out the study, told TechXplore. ""We feel that the producers, directors, actors and the rest of the large production family are doing something unique in the history of movie making, so we set out to quantify that.""The study carried out by Roughan and his colleagues Lewis Mitchell and Tobin South lies at the intersection between statistics, computer science and data science. The researchers collaborated with the data science team at the University of Adelaide, who has been working on a wide range of projects studying the internet, media, and biology. ""In biology there is a need to measure the ecological diversity of a habitat to understand its health and resilience,"" Roughan explained. ""Biologists use a type of measurement that we thought could apply to movies. The hope is that this measurement might be as valuable in analyzing movies as it is in the study of biodiversity.""Roughan and his colleagues applied a metric commonly used in ecology research to movie casts. This metric is based on the notion of Shannon-entropy, which describes the inherent uncertainty of the distribution of species in a given region, with a higher uncertainty suggesting that there is greater diversity. ""Simply put, if it is harder to guess what species you are observing (assuming you know nothing about taxonomy) at any given moment, there must be more possibilities out there,"" Roughan said. ""An analogy could be a multiple choice question- if it is harder to guess the answer, then there is more entropy. Think of it as measuring how many effective answers there are to the question. Some answers may be obviously wrong, so you don't count them seriously.""In their study, the researchers showed that an entropy-based metric can be generalized using a statistical method called Jensen-Shannon divergence, ultimately offering a measure of the similarity of characters appearing in different movies. This could be particularly useful in recommender systems for media streaming services, such as Netflix, Amazon Prime Video, etc. ""The size of a cast of characters is surprisingly hard to define,"" Roughan explained. ""There are so many small parts that are never-the-less important. Some are credited and many are not, but even the standard for what warrants credit is surprisingly variable. In ecology, they have a similar problem. It's hard to count all the species in a region. However, they have been using a metric based on Shannon entropy to get a grip on that problem.""The application of entropy in contexts other than biology has already been achieved in previous works, for instance to quantify the size of a person's vocabulary. Roughan and his colleagues used it to measure the most effective number of characters for movies, focusing on Marvel movies. Their analyses were mostly based on data from public sources, such as transcribed movie scripts, yet the researchers also created a new dataset specifically for this study. ""We watched the entire MCU again (that was the fun bit) and annotated it with information about the conflicts in the movies,"" Roughan said. ""That allowed us to measure how much each character participated in each movie. From there the entropy calculation is actually pretty easy mathematics.""Based on the data they gathered, the researchers compared different Marvel movies based on their cast sizes. This allowed them to identify patterns in the data, for instance clustering movies into groups based on particular cast characteristics. ""The biggest surprise for us was that the effective cast size is correlated with the profitability of the movies, with a bigger role-call translating in bigger profits,"" Roughan said. ""However, you have to be very careful about such results. What we observe is only a correlation—we can't get causation from that. We think the true reason for the correlation isn't just that audiences like bigger casts. The real reason is part of the uniqueness of the MCU.""According to Roughan, MCU producers created a series of movies that pave the way towards the assembly of Marvel characters. They first released movies that focused on individual characters, such as Iron Man, Captain America and Thor, then ultimately featured all of these characters as part of the Avengers team. They then repeated this process by releasing origin movies for new characters, leading to increasingly bigger ""teams."" ""That took a special kind of vision, to be willing to develop these characters over multiple movies to build up to an amazing culmination over a period of years,"" Roughan added. ""It's so different from the typical franchise, which is a series of sequels (and sometimes prequels) with roughly the same set of characters."" Although the results gathered by Roughan and his colleagues do not clarify whether cast sizes have directly influenced profits made from Marvel movies, they offer some interesting insight about the correlation between these two factors. In addition, the researchers showed how metrics used in ecology research can be applied to studies that focus on entirely different topics. ""I think we are just scraping the surface here,"" Roughan said. ""What makes a movie or a franchise work is tremendously complex, and you cannot undervalue the contributions of the brilliant directors, actors and other artists who created these movies. Historically, media analysis has been in the hands of social scientists, who analyze the human pieces of the puzzle, identify tropes, and describe how we feel about movies.""According to Roughan, data science could soon aid our understanding of many different research areas. For example, by analyzing the large amount of data collected over the years, data scientists could better understand factors associated with the success (or failure) of movies, as well as TV-series, books, and so on. Roughan believes that this shift in the perceived value of data science resembles what happened a few decades ago, when sports teams started realizing that hard data and statistics could drive them towards victory. In the case of movies, studies such as the one carried out by him and his colleagues could ultimately inform new productions, providing valuable insight into factors that might determine their failure or success.  ""At a deeper level, stories are so important for humans,"" Roughan said. ""It is fair to say, I think, that stories are what make us human; what differentiates us from the rest of the natural world. We would really like to make a contribution to understanding how and why that is so.""
                                                                                                                        "
Do passengers prefer autonomous vehicles driven like machines or like humans?,https://techxplore.com/news/2019-07-passengers-autonomous-vehicles-driven-machines.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/dopassengers.jpg,Automotive,"Jul 04, 2019","Passenger and pedestrian confidence and acceptance will be key to the future and development of autonomous vehicles so researchers at WMG at the University of Warwick have just conducted and reported an experiment to see which autonomous vehicles driving style engendered the highest levels of confidence among autonomous vehicles passengers—driving with full machine efficiency, or driving in a way that emulates average human driving. The surprising result was that neither was optimal but that a blend of both might be best.
                                              The researchers took 43 volunteers into a large warehouse designed to resemble a pedestrianised area in a town centre with a series of routes that included a range of junctions. Half were given 4 journeys around the route in an autonomous vehicle driving with full machine efficiency using all its capabilities to drive in as safe and efficient manner as possible while the others were given 4 journeys around the route in autonomous vehicles that tried to closely emulate average human driving patterns. They then scored the level of trust in the autonomous vehicles. The result has have just been published in the journal Information.The overall result was that there was only a marginal difference in trust between the two driving methods. The efficient machine method was slightly favoured but even that small gap between the two driving styles narrowed over the four runs. What was noticeable for both the ""machine"" and ""human"" driving styles is that confidence in both grew with each new round suggesting that simple familiarity and growing accustomed to the experience will be one of the most effective ways of quickly building trust and acceptance of autonomous vehicles once their use becomes more widespread.Dr. Luis Oliveira from WMG at the University of Warwick and the lead author on the paper said:""The overall trust in both driving methods grew with every run. In the machine-like driving style this was steady upwards curve throughout the four journeys but in human-like behaviour there was a particularly steep change upwards in the scores between runs 2 and 3. The passengers in the experiment also acknowledged that future generations may be more comfortable with AVs and its features, as they learn to live with the new technology.""The researchers also asked the participants to give some narrative about their experience and this showed that there were advantages on both modes of driving that may therefore need to be blended together in any future final package. The researchers' literature review and warehouse experiment made clear that there re were two particularly clear lessons to be learned:Smooth speed change—Past studies had already shown that Human drivers' tendency is to brake most at the start of any manoeuvre that requires deceleration whilst the totally automated driving programmes applied speed changes more gradually and efficiently. Human passengers preferred the comfort of the smoother changes of acceleration and deceleration provided by the machine driving methods.Sharp turns—A common complaint was a feeling that the vehicles were performing uncomfortable and worrying sharp turns. This feeling was actually expressed by both those in the machine and Human style driving set ups but it was much more noticeable in the machine-like driving style condition. One typical negative comment was ""what you'd expect from a driver is a bit of a gradual turn….there were moments where it was accelerating around corners, I think it catches you unaware.""WMG's Dr. Luis Oliveira said:""This shows that the challenge is that the speed and trajectory of autonomous vehicles should be finely controlled, but at the same time the vehicle should be assertive to provide the benefits of automated driving.""However it was the AV's behaviours at junctions in the WMG University of Warwick warehouse test that produced the most diverse and surprising reactions. The machine driven AVs were left to make use of all of their sensors and ability to communicate with vehicles that may out of line of sight to decide whether to enter a junction. If their sensors said it was safe and their communications with other vehicles indicated no approaching threats they would simply enter the junction without stopping. If however they detected a vehicle that they believed should have right of way—even if it was not yet visible to the human passenger they would stop and let that vehicle pass. In contrast The AV's emulating human driving would always stop at a junction and would even edge into the junction as if the peek at what the oncoming traffic might be.The reactions to those two different approaches were very varied and surprising.Some liked the human approach with one saying that the AV was ""…probably trying to inspire confidence in the passenger, I'm guessing, in terms of like the way it behaved, kind of quite similar to a human, it's only ever going to inspire confidence I think it's because that's what we're used to"".Some also liked the machine driving approach of stopping at junctions even though there was no visible issue but because it was in communication with another out of sight vehicle that it perceived had right of way. One passage said: ""it stopped at a junction, because I assume it knew that something was coming, as opposed to it reacting to seeing something coming"".Equally there was dislike for both the human and machine driving methods of handling a junction.Some perceived problems with the machine approach of just entering the junction if it believed it to be clear to do so with one saying that they were concerned about vulnerable road users. ""..such as pedestrians or cyclists that could have been there that don't communicate with the pod. That may be a safer way of doing it rather than flying around the corner"".However others were greatly surprised at the ""human"" driving method AV stopping at every junction as they saw it not just as waste of the machines capabilities to scan and communicate ahead to understand traffic. They were frustrated that the vehicle was not ""more assertive"" One passenger saying ""sometimes I didn't expect it to stop, because I thought the other pod was a bit further away but then it did, so I guess it's cautious…if I was driving I'd probably have gone"". Another passenger said ""If I was in an autonomous pod with sensors giving a 360-degree view at all times, I'd expect the vehicle to instantaneously know whether it was safe or not, and not need to edge out"".A further passenger who tested the human-like version, commented that a machine driving like a human and trying to look around the corners seemed ironically unnatural saying: ""I think it was a bit unexpected because my expectation with the pods is that that there would be some un-naturalism to it rather than a human driver"".Despite this seeming mass of contradictions in views about how AVs should handle junctions the research team do think there are valuable lessons to be learned even here. In particular:There is clearly a need to give the general public the details of the driving systems, for example, the recent technological features such as vehicle to vehicle communicationFor passengers in a vehicle consideration should be given to having a display and/or audio information that shares some of the information the vehicle is using so users can understand that the system is aware of hazards beyond the field of view.There may be some merit in presenting the full benefits of the most efficient methods of machine based driving progressively when mass use is first introduced, so that passengers can build confidence over time"
Canon sees crowdfunding opportunity for little clippable camera,https://techxplore.com/news/2019-07-canon-crowdfunding-opportunity-clippable-camera.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/canonseescro.jpg,Consumer & Gadgets,"Jul 04, 2019","Canon has turned to crowdfunding for a camera. The camera, said the campaign page, is feature-packed: 13.0 Megapixel 1/3-inch CMOS sensor, full HD video shooting at 1080p up to 60fps, Bluetooth and wireless connectivity.
                                              It's tiny. It's clippable. It's shockproof. It's go-anywhere. And, it had some observers scratching their heads wondering why. Dami Lee, The Verge: ""Or maybe clip it onto your dog or cat's collar so you can see the world from your pet's POV?""Generally, observers envisioned the camera good for outdoor adventures. This outdoor camera is called the IVY REC.Lee said the size is about that of a USB flash drive.How it works: IVY REC wirelessly connects via Wi-Fi or Bluetooth to the companion CanonMini Cam App. The app serves to preview shots and also to transfer them to your phone. So, the app turns your smartphone into a live view display and allows for the wireless transfer of photos and video.""The empty square space of the clip doubles as a viewfinder, and there's a single dial on the back that lets you switch between modes,"" Lee said.A number of tech sites took note that this was a 13-megapixel 1/3-inch CMOS sensor that can record video at up to 60 frames per second in addition to capturing stills.(OK, said Jon Fingas in Engadget, so it ""won't win the image quality wars."" However, it's built around a design that should be safer to use than your phone if you are out in the woods or at the beach.)It is waterproof for 30 minutes for depths of up to three feet.What's next? The campaign is not yet up and running and there is no price listing as of yet. Instead, there is a sign-up exercise.You can sign  up to be notified when the campaign begins and get 30 percent off the retail price if you're an early backer, said Lee on Wednesday.The question is, why would Canon crowdfund anything?  A known brand begging for dollars? What's up with that?PetaPixel  stepped in to argue that it's not about dollars. It's about smelling the roses or alternatively averting the financial risks. Usman Dawood: ""Crowdfunding websites are generally used as a way to determine the demand of a product. This is one of the key benefits of using a website like Indiegogo. Raising a few million on a crowdfunding website is a brilliant way to measure the demand for any new product and mitigates a significant amount of risk.""Few takers? Then the company moves on with minimal loss. On another point, Gannon Burgett, DPReview, reminded readers  of Canon's past remarks in a past interview: ""Canon executives noted the company is determined 'to capture as many customers as [it] can' and expressed the belief that 'there's a new genre of capturing: a new casual capturing market,' of sorts that has 'potential for new developments.' ""Moreover, a well-known brand name like Canon may seem out of character in a crowdfunding site but it is a practical way of taking the pules of potential public interest for such a device.Canon wants to capture as many new customers as possible, especially casual photographers.So, now that the why-would-Canon-do-crowdfunding has been addressed the next question is why anyone would want this camera. Gizmodo's reference to it as ""a tiny barebones shooter"" is excuse enough when you just want to shoot to capture a moment in the great outdoors without worrying over an ""expensive device getting wet, or dropped, or even scratched."" That way, you use ""a cheap tiny camera clipped to your belt, always at the ready,"" not your phone.Canon would gladly echo that point. Its own pitch said ""No fragile screen to crack—the clip doubles as a viewfinder. The upcoming companion CanonMini Cam App enables live preview on your phone. Transfer and share photos & videos wirelessly.""""While it's not quite as rugged as a full-fledged action camera, it should help you spend more time enjoying moments and less time worrying about breaking your electronics or framing the perfect picture,"" said Fingas.
                                                                                                                        "
A new genetic algorithm for traffic control optimization,https://techxplore.com/news/2019-07-genetic-algorithm-traffic-optimization.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/anewgenetica.jpg,Computer Sciences,"Jul 03, 2019","Researchers at the University of Technology Sydney and DATA61 have recently developed a new method for optimizing the timing of signals in urban environments under severe traffic conditions. Their approach, presented in a paper pre-published on arXiv, entails the use of genetic algorithms (GAs), a popular computer science technique for solving optimization problems.
                                              ""The idea of this research work came from various drives with my car in the city of Sydney, which is often affected by traffic incidents, causing a large amount of delay and increased road congestion,"" Tuo Mao, one of the researchers who carried out the study, told TechXplore. ""This made me wonder: How can we solve this problem with the aid of advanced computer science techniques?"" Traffic control signals are the most widespread tools to control and manage road traffic in densely populated urban environments. A traffic signal's settings, also known as signal control plan, can affect road traffic significantly, particularly when disruptions first arise.So far, the majority of proposed solutions for traffic control optimization are designed to work under normal traffic conditions. This is because optimizing a traffic light's control plans after an incident has occurred or when traffic is at a peak is a particularly challenging task, especially if multiple lanes or an entire road section are affected. Contrarily to most previous works, Mao and his colleagues set out to achieve traffic signal control optimization under severe traffic conditions using GAs. GAs are a computer science technique inspired by the biological evolution observed in humans, which is designed to naturally select the most optimal solutions among an initial set of possibilities. ""GAs are commonly used in optimization problems (e.g., finding the best phase duration that would minimise travel time in an intersection) by using bio-inspired functions such as individual mutation, crossover, and selection of best individuals to carry on the best genes of a population—in our case, best signal phases,"" Mao said. ""We thought that GAs would be a fantastic solution to solve this problem and decided to use them to generate the optimized traffic signal plans for the incident affected area."" The GA developed by Mao and his colleagues essentially explores all possible traffic signal control plans for a given intersection (e.g. the green time for ""right turn"" signals, ""go straight' signals, etc.). Its key objective is to minimize the total travel time in an area affected by a road accident by identifying the best combination of signal phases across all intersections within that area. ""We first generate a large number of traffic control plans, including different phase durations evenly distributed in a large numerical space, which constitute the first generation of individuals from the entire population,"" Mao explained. ""Then we apply selection, crossover and mutation in order to introduce more randomness in exploring the space of all possibilities, and select only the best candidates to carry on the optimization in a next generation.""Subsequently, the approach devised by Mao and his colleagues evolves the original population for a specific number of generations until the majority of individuals within that population are similar, and it has reached an optimal solution. The GA's final outcome is an optimized traffic signal control plan for all traffic lights in areas affected by road accidents. While past studies have proposed several other traffic signal control optimization techniques, most of these are based on traffic modeling and knowledge-based expert (i.e., heuristic) systems. These systems passively react to observed traffic conditions and are hence unable to actively propose solutions for reducing congestion caused by road accidents. ""Our method has three key advantages,"" Mao explained. Firstly, it considers non-recurrent traffic incidents, as we input the incident to the model actively after someone reported it, therefore the traffic signal control plan is aware of the incident and can respond faster. Secondly, it considers the rerouting behavior of drivers by applying a dynamic traffic assignment, which considers the road capacity drop caused by the traffic incidents. Finally, our method is efficient for exploring many possibilities of signal control plans."" The researchers evaluated their technique using a four-intersection network designed in AIMSUN, a renowned traffic modeling platform. They constructed three different scenarios in which the GA had to optimize traffic signal timings under both normal conditions and with severe traffic. In these tests, they observed that when traffic signal control plans can be adapted to a change of route by drivers after a traffic accident has occurred, congestion tends to dissipate faster.  ""When using our method, we improved drivers' total travel time by 40.76% compared to applying no response at all (i.e. no control over the signal phasing),"" Mao said. "" Our research could provide suggestions for traffic management centres on how to act when a fresh incident happens, as a part of a routine for managing a better traffic response.""In the future, the GA developed by Mao and his colleagues could aid the development of more effective traffic control systems. According to the researchers, by advancing their technique's data streaming capabilities and computational performance they could ultimately allow it to automatically optimize traffic signals, actively responding to live road incidents. ""We are currently applying the method to a more complicated network and even a larger network from the city of Sydney,"" Mao said. ""We are also researching to further shorten the computation time and further increase efficiency by coupling the GA with machine learning, which could speed-up the convergence rate towards the best solutions.""
                                                                                                                        "
AI-designed heat pumps consume less energy,https://techxplore.com/news/2019-07-ai-designed-consume-energy.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/1-aidesignedhe.jpg,Engineering,"Jul 03, 2019","In Switzerland, 50 to 60 percent of new homes are equipped with heat pumps. These systems draw in thermal energy from the surrounding environment—such as from the ground, air, or a nearby lake or river—and turn it into heat for buildings.
                                              While today's heat pumps generally work well and are environmentally friendly, they still have substantial room for improvement. For example, by using microturbocompressors instead of conventional compression systems, engineers can reduce heat pumps' power requirement by 20 to 25 percent (see inset) as well as their impact on the environment. That's because turbocompressors are more efficient and ten times smaller than piston devices. But incorporating these mini components into heat pumps' designs is not easy; complications arise from their tiny diameters (<20 mm) and fast rotation speeds ( greater than 200,000 rpm).At EPFL's Laboratory for Applied Mechanical Design on the Microcity campus, a team of researchers led by Jürg Schiffmann has developed a method that makes it easier and faster to add turbocompressors to heat pumps. Using a machine-learning process called symbolic regression, the researchers came up with simple equations for quickly calculating the optimal dimensions of a turbocompressor for a given heat pump. Their research just won the Best Paper Award at the 2019 Turbo Expo Conference held by the American Society of Mechanical Engineers.1,500 times faster The researchers' method drastically simplifies the first step in designing turbochargers. This step—which involves roughly calculating the ideal size and rotation speed for the desired heat pump—is extremely important because a good initial estimate can considerably shorten the overall design time. Until now, engineers have been using design charts to size their turbocompressors—but these charts become increasingly inaccurate the smaller the equipment. And the charts have not kept up to date with the latest technology.That's why two EPFL Ph.D. students—Violette Mounier and Cyril Picard—worked on developing an alternative. They fed the results of 500,000 simulations into machine-learning algorithms and generated equations that replicate the charts but with several advantages: they are reliable even at small turbocompressor sizes; they are just as detailed as more complicated simulations; and they are 1,500 times faster. The researchers' method also lets engineers skip some of the steps in conventional design processes. It paves the way to easier implementation and more widespread use of microturbochargers in heat pumps.The benefits of microturbocompressorsConventional heat pumps use pistons to compress a fluid, called a refrigerant, and drive a vapor-compression cycle. The pistons need to be well-oiled to function properly, but the oil can stick to the heat exchanger walls and impairs the heat transfer process. However, microturbocompressors—which have diameters of just a few dozen millimeters—can run without oil; they rotate on gas bearings at speeds of hundreds of thousands of rpm. The rotating movement and gas layers between the components mean there is almost no friction. As a result, these miniature systems can boost heat pumps' heat transfer coefficients by 20 to 30 percent.This microturbocharger technology has been in development for several years and is now mature. ""We have already been contacted by several companies that are interested in using our method,"" says Schiffmann. Thanks to the researchers' work, companies will have an easier time incorporating the microturbocharger technology into their heat pumps.
                                                                                                                        "
Robot uses photonic sensors to pick strawberries in gee-whiz numbers,https://techxplore.com/news/2019-07-robot-photonic-sensors-strawberries-gee-whiz.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/5d1cad567d616.jpg,Robotics,"Jul 03, 2019","Robots engineered for picking delicate, soft fruits have not made out very well, for several reasons. Tricky business. Squashed fruit was one drawback and the other was the machine not being smart enough to discern which berry was ripe and which was rotten.
                                              Lucy Hooker, BBC News, said harvesting soft fruit mechanically represented a huge challenge. She said, ""each berry needs to be located, even if it's behind a leaf, assessed for ripeness and then harvested and boxed with enormous care to avoid bruising.""Well, the challenge looks a lot less daunting now that Rubion has made its debut, with strawberry-picking features that have impressed. Can the robot discern which fruits are ripe for picking? Check. Jon Excell, The Engineer named two key features of this robot— smart photonics and a patented soft-touch gripper. The robot can both pick strawberries and sort them by size or weight and pack as it goes along. The strawberries are picked based on ripeness and size. They are packaged in varied categories.Who is behind Rubion? Design Products & Applications reported  on its ""photonics"" connection, in the name of photonics innovation incubator, which is ACTPHAST 4.0. The latter supported Octinion, a company focused on robotic solutions for agriculture and food. Octinion is a Belgium-based company. ACTPHAST 4.0 is an SME 'incubator' that helps existing and fledgling businesses with innovation in photonics, and on this occasion it provided the calibration of the RGB camera built into the robot.""ACTPHAST 4.0, helped considerably to detect the perfect ripe strawberry,"" Octinion's Dr. Jan Anthonis said.Meet Rubion, asks the promotional video, and calls it the world's first commercial strawberry picking robot. The robot is said to pose ""An answer to your recruiting, training and housing needs.""Human pickers can collect around 50 kilograms in a day but take breaks.The Scottish Farmer walked readers through the impressive numbers of yield and labor output that would result in  using the robots, ""promising a 'revolution' in harvesting soft fruit, with a workrate of 11,500 berries  in a 16-hour day. The description said they were bruise-free, every 5 seconds, with the robot's delicate clasping mechanism, and with the ability to deliver between 180 and 360 kilograms every single day.The robot's launchers cleverly chose the robot's debut to coincide with Wimbledon week's famed berry consumption. That way, they too could run some impressive numbers to build awareness for Rubion.The makers, said The Scottish Farmer, claimed 14 machines in less than seven days could pick and package ""the 34,000 kilos of unblemished strawberries usually consumed by the crowd at the tennis tournament.""The Scottish Farmer said the machine, and all within a 5-second picking cycle,  (1) analyzes colors of each fruit and (2) assesses if the fruit is ripe enough for picking via the clasping mechanism. So, where does that leave human workers? Gordon Davidson quoted Jan Anthonis of the company, who said, ""Rotting and unpicked fruit from a lack of human pickers on farms all over the world could soon be tackled with robots.""""You no longer need to worry about finding the right people but you can focus on tomorrow,"" according to the company web site. Turn the question over a bit. The people one no longer needs to worry about is all because the focus on tomorrow might be robots. Should those people worry?Inevitably, a reader comment on one site, The Engineer, asked what would happen to farm labor if robots were to replace them: ""The real issue here is what of the unskilled workers or seasonal workers that are trying to earn some extra money? How do you replace these jobs? Just because we can, does not mean we should.""The Belgium-based company have performed trials this summer in partnership with growers in the UK and continental Europe, said Hooker,  BBC News""Photonics"" is about generating and harnessing light and other forms of radiant energy whose quantum unit is the photon, according to OP-TEC, The National Center for Optics and Photonics Education. The technology involves ""cutting-edge uses of lasers, optics, fiber-optics, and electro-optical devices"" in alternate energy, manufacturing, health care, environmental monitoring and other fields.OP-TEC also said lasers and other light beams were the ""preferred carriers"" of energy and information for applications such as agriculture, measuring product quality in food and test systems for industry.
                                                                                                                        "
A bio-inspired flow-sensing cupula for submersible robotics,https://techxplore.com/news/2019-07-bio-inspired-flow-sensing-cupula-submersible-robotics.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/3-abioinspired.jpg,Robotics,"Jul 02, 2019","Nature can be a precious source of inspiration for researchers developing robots and artificial intelligence (AI) systems. Studies in submersible robotics, for instance, have often tried to replicate or incorporate mechanisms observed in aquatic life, such as fish locomotion patterns and shark skin textures.
                                              A team of researchers at the U.S. Naval Research Laboratory and the U.S. Naval Undersea Warfare Center have recently developed a capacitive flow-sensing cupula inspired by superficial neuromasts, which are essentially structures on the body of fish and amphibians that can detect the flow of water. This cupula, presented in a paper published in MDPI, exhibits a high sensitivity of 0.05 picofarad per millimeter (pF/mm) and could be applied to a variety of robots and vehicles designed to be deployed underwater. ""The U.S. Naval Research Laboratory, along with many other institutions, is exploring nature-inspired means to achieve increased efficiency and maneuverability in underwater robots,"" Charles Rohde, one of the researchers who carried out the study, told TechXplore. ""In essence, creating an artificial fish offers many benefits over traditional propeller-driven designs. If we look at biological counterparts, though, we see that their success is due to more than just the mechanics and body motion; fish have arrays of sensors along their bodies.""Fish have a series of so-called lateral line sensors that provide flow condition feedback, allowing them to orient themselves underwater and detect nearby objects. Rohde and his colleagues wanted to replicate these sensors and mimic their properties to enhance the performance of underwater vehicles. The biological cupulas observed in fish are comprised of gel embedded with sensor hairs, which are attached to the aquatic animal's brain via a series of nerves. The artificial cupula developed by the researchers, on the other hand, is made up of silicone rubber embedded with liquid metal sensing plates, which are attached to a microcontroller using wires. A further difference between naturally occurring cupulas and the artificial one developed by the researchers is that while the former employs electrochemical signals, the latter is capacitive (i.e. like smartphone touchscreens, it relies on changes in electric fields). In contrast with touchscreens, the bio-inspired device does not interact with external objects (e.g. human fingers). Instead, it consists of liquid metal plates moving and deforming relative to one another.""The liquid metal (gallium-indium) plates form two capacitive sensors that deform based on forces imparted on the silicone cupula by fluid flow,"" James Wissman, another researchers involved in the study, explained. ""As the cupula deforms, the liquid metal plates inside move closer or farther from each other, changing the capacitance between them. A microcontroller records this change in capacitance, which can be related to the outside fluid flow rate through experimentation and mathematical modeling.""The capacitive sensors developed by the researchers have a high sensitivity and can also be arranged in arrays. For instance, dozens of these sensors could be arranged across an underwater robot in a lateral line, in order to capture and track water flow characteristics. These sensing cupulas are soft; thus they can be integrated with artificial skin materials without adding rigidity to bio-inspired machines. ""There are several other cupula- and hair-based flow sensors published in the literature, but we were surprised to find only one other underwater, seal whisker-inspired example that was capacitive in nature,"" Rohde said. ""Our results show that capacitive sensing is a very promising approach, and we hope that our publication will encourage others to explore this method.""Rohde, Wissman and their colleagues fabricated their bio-inspired sensor using lost wax and vacuum injection techniques. They then carried out a series of preliminary tests to evaluate its performance. Compared to other capacitive devices, their sensor incorporates transducers into the cupula itself, rather than at its base. In their evaluations, this particular aspect of the sensor's fabrication proved to be very effective, leading to more advanced sensing capabilities than those observed in previously developed capacitive devices. ""Aside from the sensor itself, another important aspect is the fabrication process,"" Wissman said. ""To create such a complex structure inside of a small silicone structure, we used a unique combination of sacrificial molding (think lost-wax casting) and vacuum-injection of liquid metal. This could easily be extended to other devices, such as complex 3-D wiring or antennas.""The sensing device developed by Rohde, Wissman and his colleagues could have a wide variety of applications in the field of submersible robotics, as it enables the development of robots that can navigate underwater environments more effectively. In their future work, the researchers plan to miniaturize their device, which is currently 5mm tall; 50 times bigger than the neuromasts observed in fish. A smaller version of the sensor could allow for a more direct measurement of boundary layer flow conditions, even closer to a robot's water-facing surface. In order to miniaturize the sensor, however, the researchers will need to change their fabrication methods. So far, Wissman and his colleagues have primarily focused on steady (or slowly changing) flows of water, but superfast flow variations (i.e. >1,000-10,000 times per second) associated with turbulence and vortices could provide deeper insight about a robot's surrounding environment. In their upcoming studies, the researchers would hence like to broaden the scope of their work by including these flow variations and looking at faster data acquisition techniques. ""We also plan to assemble an array of artificial cupulas—an artificial lateral line—that can be attached to a submersible robot,"" Wissman said. ""The culmination of this project would be to watch an autonomous robotic fish, with the aid of our embedded sensors, successfully navigate a pool with obstacles and currents.""
                                                                                                                        "
Tiny motor can 'walk' to carry out tasks,https://techxplore.com/news/2019-07-tiny-motor-tasks.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/tinymotorcan.gif,Robotics,"Jul 02, 2019","Years ago, MIT Professor Neil Gershenfeld had an audacious thought. Struck by the fact that all the world's living things are built out of combinations of just 20 amino acids, he wondered: Might it be possible to create a kit of just 20 fundamental parts that could be used to assemble all of the different technological products in the world?
                                              Gershenfeld and his students have been making steady progress in that direction ever since. Their latest achievement, presented this week at an international robotics conference, consists of a set of five tiny fundamental parts that can be assembled into a wide variety of functional devices, including a tiny ""walking"" motor that can move back and forth across a surface or turn the gears of a machine.Previously, Gershenfeld and his students showed that structures assembled from many small, identical subunits can have numerous mechanical properties. Next, they demonstrated that a combination of rigid and flexible part types can be used to create morphing airplane wings, a longstanding goal in aerospace engineering. Their latest work adds components for movement and logic, and will be presented at the International Conference on Manipulation, Automation and Robotics at Small Scales (MARSS) in Helsinki, Finland, in a paper by Gershenfeld and MIT graduate student Will Langford.Their work offers an alternative to today's approaches to constructing robots, which largely fall into one of two types: custom machines that work well but are relatively expensive and inflexible, and reconfigurable ones that sacrifice performance for versatility. In the new approach, Langford came up with a set of five millimeter-scale components, all of which can be attached to each other by a standard connector. These parts include the previous rigid and flexible types, along with electromagnetic parts, a coil, and a magnet. In the future, the team plans to make these out of still smaller basic part types.Using this simple kit of tiny parts, Langford assembled them into a novel kind of motor that moves an appendage in discrete mechanical steps, which can be used to turn a gear wheel, and a mobile form of the motor that turns those steps into locomotion, allowing it to ""walk"" across a surface in a way that is reminiscent of the molecular motors that move muscles. These parts could also be assembled into hands for gripping, or legs for walking, as needed for a particular task, and then later reassembled as those needs change. Gershenfeld refers to them as ""digital materials,"" discrete parts that can be reversibly joined, forming a kind of functional micro-LEGO.The new system is a significant step toward creating a standardized kit of parts that could be used to assemble robots with specific capabilities adapted to a particular task or set of tasks. Such purpose-built robots could then be disassembled and reassembled as needed in a variety of forms, without the need to design and manufacture new robots from scratch for each application.Langford's initial motor has an ant-like ability to lift seven times its own weight. But if greater forces are required, many of these parts can be added to provide more oomph. Or if the robot needs to move in more complex ways, these parts could be distributed throughout the structure. The size of the building blocks can be chosen to match their application; the team has made nanometer-sized parts to make nanorobots, and meter-sized parts to make megarobots. Previously, specialized techniques were needed at each of these length scale extremes.""One emerging application is to make tiny robots that can work in confined spaces,"" Gershenfeld says. Some of the devices assembled in this project, for example, are smaller than a penny yet can carry out useful tasks.To build in the ""brains,"" Langford has added part types that contain millimeter-sized integrated circuits, along with a few other part types to take care of connecting electrical signals in three dimensions.The simplicity and regularity of these structures makes it relatively easy for their assembly to be automated. To do that, Langford has developed a novel machine that's like a cross between a 3-D printer and the pick-and-place machines that manufacture electronic circuits, but unlike either of those, this one can produce complete robotic systems directly from digital designs. Gershenfeld says this machine is a first step toward to the project's ultimate goal of ""making an assembler that can assemble itself out of the parts that it's assembling.""""Standardization is an extremely important issue in microrobotics, to reduce the production costs and, as a result, to improve acceptance of this technology to the level of regular industrial robots,"" says Sergej Fatikow, head of the Division of Microrobotics and Control Engineering, at the University of Oldenburg, Germany, who was not associated with this research. The new work ""addresses assembling of sophisticated microrobotic systems from a small set of standard building blocks, which may revolutionize the field of microrobotics and open up numerous applications at small scales,"" he says.
                                                                                                                        "
Ossia suits up for new day in wireless charging,https://techxplore.com/news/2019-07-ossia-day-wireless.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/ossiasuitsup.jpg,Consumer & Gadgets,"Jul 02, 2019","Technology advances by leaps, bounds—and stagnates in a stubborn flat line. Technology has showcased machines that can learn how to make a sophisticated pizza, identify individuals by heartbeat and bring self-driving cars to move, stop and park. We are still, however, sentenced to charging pads and holding patterns on walls to juice our devices.
                                              Bellevue, Washington-based Ossia wants to be in the frontline of game-changers. They are promoting their solution for wireless charging. Ossia has announced it received authorization from the U.S. Federal Communications Commission for its wireless power system.As it is called, Ossia's Cota Real Wireless Power delivers power over-the-air, at a distance, and without the need for line-of-sight.""After months of collaboration with the FCC's Office of Engineering and Technology, I'm thrilled to announce that Ossia received official notice on June 27th, 2019, of equipment authorization for Cota under FCC Part 15 and Part 18,"" said the company founder Hatem Zeine.The news release stated, ""Ossia's initial certification covers a Cota transmitter operating at 2.4 GHz for deployments in commercial, industrial, and business environments, at a distance of up to one meter.""Cota uses radio waves to provide power. With Cota, it is all about using 2.4-gigahertz radio waves. IEEE Spectrum's Evan Ackerman in 2016 had already found the Cota approach interesting. ""The wireless power that everybody wants and nobody has is the kind where all of your devices are charging themselves wherever they happen to be, whether you're using them or wearing them or not. That is what Ossia is offering with Cota.""Real Wireless Power was FCC Certified under Parts 18 and 15. The system is available to be marketed and sold in the U.S. IEEE Spectrum's headline read, ""Ossia's Wireless Charging Tech Could Be Available By Next Year.""Details about the certification news was discussed in the company release. ""Ossia's initial certification covers a Cota transmitter operating at 2.4 GHz for deployments in commercial, industrial, and business environments, at a distance of up to one meter.""Some reasons for why this matters: (1) It validates the safety of Cota delivering wireless power at a distance, and (2) paves the way for enablement of devices and sensors limited by the use of wires or batteries. The tech met Specific Absorption Rate (SAR) requirements for safety, said the release. The charging technology may be available next year. Devices based on this first equipment authorization are expected to be available in the market in 2020 through Ossia's commercial partners.If general references to ""wireless charging"" seem vague, you would not be alone. In fact, Ossia's team would agree that this term wireless charging ""gets thrown around a lot these days.""Moreover, Michael Koziol, an associate editor at IEEE Spectrum,  sees  supplying power wireless charging as a reality that never quite lived up to the hype: ""While supplying power wirelessly seems like a promising idea in theory, the technology has been explored for years and its reality has never quite lived up to the hype. In all likelihood, the most sophisticated example you've seen of wireless charging is something like the wireless charging pads on coffee shop tables."" How the tech works:""The Cota Power Receiver, embedded into any device initiates the 'conversation' by sending a beacon signal to find a Cota Power Transmitter. The transmitter then sends power back in the same path. This 'conversation' between device and transmitter happens 100x/second to send power safely to devices at a distance while in motion.""Using a cloud service, you can select which device to power. press the start charging button and the device will start charging.""The received power is enough to charge a wearable, power an iBeacon device, or power any device that consumes as much power as a typical smartphone,"" said an Ossia blog post.The blog addressed safety: ""Cota was tested with humans (actually, simulations of humans) in the room to determine how much signal their bodies absorbed."" Cota passed the test, one of the requirements for FCC certification, it said.Koziol explained how the company sees two potential uses for its technology. The first is to use Ossia's Forever Batteries, announced at CES 2018, to replace traditional AA batteries in devices. At CES 2018, the concept of the Forever Battery was presented by CEO Mario Obeidat.  The other option is removing a device's battery altogether and using antennas to power battery-less devices. ""Ossia doesn't plan to manufacture Cota-enabled devices itself,"" said Koziol. ""Instead, it wants to license the tech to commercial partners that Ossia hopes will have devices featuring Cota on shelves by next year.""
                                                                                                                        "
Study shows how to improve production at wind farms,https://techxplore.com/news/2019-07-production-farms.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/windfarm.jpg,Energy & Green Tech,"Jul 01, 2019","What's good for one is not always best for all.
                                              Solitary wind turbines produce the most power when pointing directly into the wind. But when tightly packed lines of turbines face the wind on wind farms, wakes from upstream generators can interfere with those downstream. Like a speedboat slowed by choppy water from a boat in front, the wake from a wind turbine reduces the output of those behind it.Pointing turbines slightly away from oncoming wind—called wake-steering—can reduce that interference and improve both the quantity and quality of power from wind farms, and probably lower operating costs, a new Stanford study shows.""To meet global targets for renewable energy generation, we need to find ways to generate a lot more energy from existing wind farms,"" said John Dabiri, professor of civil and environmental engineering and of mechanical engineering and senior author of the paper. ""The traditional focus has been on the performance of individual turbines in a wind farm, but we need to instead start thinking about the farm as a whole, and not just as the sum of its parts.""Turbine wakes can reduce the efficiency of downwind generators by more than 40 percent. Previously, researchers have used computer simulations to show that misaligning turbines from the prevailing winds could raise production of downstream turbines. However, showing this on a real wind farm has been hindered by challenges in finding a wind farm willing to halt normal operations for an experiment and in calculating best angles for the turbine—until now.First, the Stanford group developed a faster way to calculate the optimal misalignment angles for turbines, which they described in a study, published July 1 in Proceedings of the National Academy of Sciences.Then, they tested their calculations on a wind farm in Alberta, Canada in collaboration with operator TransAlta Renewables. The overall power output of the farm increased by up to 47 percent in low wind speeds—depending on the angle of the turbines—and by 7 to 13 percent in average wind speeds. Wake steering also reduced the ebbs and flows of power that are normally a challenge with wind power.""Through wake steering, the front turbine produced less power as we expected,"" said mechanical engineering Ph.D. student Michael Howland, lead author on the study. ""But we found that because of decreased wake effects, the downstream turbines generated significantly more power.""VariabilityVariable output by wind farms makes managing the grid more difficult in two important ways.One is the need for backup power supplies, like natural gas-fired power plants and large, expensive batteries. In the new study, the power improvement at low wind speeds was particularly high because turbines typically stop spinning below a minimum speed, cutting production entirely and forcing grid managers to rely on backup power. In slow winds, wake-steering reduced the amount of time that speeds dropped below this minimum, the researchers found. Notably, the biggest gains were at night, when wind energy is typically most valuable as a complement to solar power.The other is the need to match exactly the amount of electricity supplied and used in a region every moment to keep the grid reliable. Air turbulence from wakes can make wind farm production erratic minute by minute—a time period too short to fire up a gas generator. This makes matching supply and demand more challenging for system operators in the very short term. They have tools to do so, but the tools can be expensive. In the study, wake steering reduced the very short-term variability of power production by up to 72 percent.Additionally, reducing variability can help wind farm owners lower their operating costs. Turbulence in wakes can strain turbine blades and raise repair costs. Although the experiment did not last long enough to prove that wake steering reduces turbine fatigue, the researchers suggested this would happen.""The first question that a lot of operators ask us is how this will affect the long-term structural health of their turbines,"" Dabiri said. ""We're working on pinpointing the exact effects, but so far we have seen that you can actually decrease mechanical fatigue through wake steering.""Modeling and long-term viabilityTo calculate the best angles of misalignment for this study, the researchers developed a new model based on historical data from the wind farm.""Designing wind farms is typically a very data and computationally intensive task,"" said Sanjiva Lele, a professor of aeronautics and astronautics, and of mechanical engineering. ""Instead, we established simplified mathematical representations that not only worked but also reduced the computational load by at least two orders of magnitude.""This faster computation could help wind farm operators use wake steering widely.""Our model is essentially plug-and-play because it can use the site-specific data on wind farm performance,"" Howland said. ""Different farm locations will be able to use the model and continuously adjust their turbine angles based on wind conditions.""Although the researchers were unable to measure a change in annual power production because of the limited 10-day duration of this field test, the next step, said Dabiri, is to run field tests for an entire year.""If we can get to the point where we can deploy this strategy on a large-scale for long periods of time, we can potentially optimize aerodynamics, power production and even land-use for wind farms everywhere,"" said Dabiri.
                                                                                                                        "
Teaching artificial intelligence to create visuals with more common sense,https://techxplore.com/news/2019-07-artificial-intelligence-visuals-common.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/1-teachingarti.jpg,Consumer & Gadgets,"Jul 01, 2019","Today's smartphones often use artificial intelligence (AI) to help make the photos we take crisper and clearer. But what if these AI tools could be used to create entire scenes from scratch?
                                              A team from MIT and IBM has now done exactly that with ""GANpaint Studio,"" a system that can automatically generate realistic photographic images and edit objects inside them. In addition to helping artists and designers make quick adjustments to visuals, the researchers say the work may help computer scientists identify ""fake"" images.David Bau, a Ph.D. student at MIT's Computer Science and Artificial Intelligence Lab (CSAIL), describes the project as one of the first times computer scientists have been able to actually ""paint with the neurons"" of a neural network—specifically, a popular type of network called a generative adversarial network (GAN).Available online as an interactive demo, GANpaint Studio allows a user to upload an image of their choosing and modify multiple aspects of its appearance, from changing the size of objects to adding completely new items like trees and buildings.Boon for designersSpearheaded by MIT professor Antonio Torralba as part of the MIT-IBM Watson AI Lab he directs, the project has vast potential applications. Designers and artists could use it to make quicker tweaks to their visuals. Adapting the system to video clips would enable computer-graphics editors to quickly compose specific arrangements of objects needed for a particular shot. (Imagine, for example, if a director filmed a full scene with actors but forgot to include an object in the background that's important to the plot.)GANpaint Studio could also be used to improve and debug other GANs that are being developed, by analyzing them for ""artifact"" units that need to be removed. In a world where opaque AI tools have made image manipulation easier than ever, it could help researchers better understand neural networks and their underlying structures.""Right now, machine learning systems are these black boxes that we don't always know how to improve, kind of like those old TV sets that you have to fix by hitting them on the side,"" says Bau, lead author on a related paper about the system with a team overseen by Torralba. ""This research suggests that, while it might be scary to open up the TV and take a look at all the wires, there's going to be a lot of meaningful information in there.""One unexpected discovery is that the system actually seems to have learned some simple rules about the relationships between objects. It somehow knows not to put something somewhere it doesn't belong, like a window in the sky, and it also creates different visuals in different contexts. For example, if there are two different buildings in an image and the system is asked to add doors to both, it doesn't simply add identical doors—they may ultimately look quite different from each other. ""All drawing apps will follow user instructions, but ours might decide not to draw anything if the user commands to put an object in an impossible location,"" says Torralba. ""It's a drawing tool with a strong personality, and it opens a window that allows us to understand how GANs learn to represent the visual world.""GANs are sets of neural networks developed to compete against each other. In this case, one network is a generator focused on creating realistic images, and the second is a discriminator whose goal is to not be fooled by the generator. Every time the discriminator 'catches' the generator, it has to expose the internal reasoning for the decision, which allows the generator to continuously get better.""It's truly mind-blowing to see how this work enables us to directly see that GANs actually learn something that's beginning to look a bit like common sense,""  says Jaakko Lehtinen, an associate professor at Finland's Aalto University who was not involved in the project. ""I see this ability as a crucial steppingstone to having autonomous systems that can actually function in the human world, which is infinite, complex and ever-changing.""Stamping out unwanted ""fake"" imagesThe team's goal has been to give people more control over GAN networks.  But they recognize that with increased power comes the potential for abuse, like using such technologies to doctor photos. Co-author Jun-Yan Zhu says that he believes that better understanding GANs—and the kinds of mistakes they make—will help researchers be able to better stamp out fakery.""You need to know your opponent before you can defend against it,"" says Zhu, a postdoc at CSAIL. ""This understanding may potentially help us detect fake images more easily.""To develop the system, the team first identified units inside the GAN that correlate with particular types of objects, like trees. It then tested these units individually to see if getting rid of them would cause certain objects to disappear or appear. Importantly, they also identified the units that cause visual errors (artifacts) and worked to remove them to increase the overall quality of the image.""Whenever GANs generate terribly unrealistic images, the cause of these mistakes has previously been a mystery,"" says co-author Hendrik Strobelt, a research scientist at IBM. ""We found that these mistakes are triggered by specific sets of neurons that we can silence to improve the quality of the image.""Bau, Strobelt, Torralba and Zhu co-wrote the paper with former CSAIL Ph.D. student Bolei Zhou, postdoctoral associate Jonas Wulff, and undergraduate student William Peebles. They will present it next month at the SIGGRAPH conference in Los Angeles. ""This system opens a door into a better understanding of GAN models, and that's going to help us do whatever kind of research we need to do with GANs,"" says Lehtinen.
                                                                                                                        "
"Smart glasses follow our eyes, focus automatically",https://techxplore.com/news/2019-07-smart-glasses-eyes-focus-automatically.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/smartglasses.gif,Engineering,"Jul 01, 2019","Though it may not have the sting of death and taxes, presbyopia is another of life's guarantees. This vision defect plagues most of us starting about age 45, as the lenses in our eyes lose the elasticity needed to focus on nearby objects. For some people reading glasses suffice to overcome the difficulty, but for many people the only fix, short of surgery, is to wear progressive lenses.
                                              ""More than a billion people have presbyopia and we've created a pair of autofocal lenses that might one day correct their vision far more effectively than traditional glasses,"" said Stanford electrical engineer Gordon Wetzstein. For now, the prototype looks like virtual reality goggles but the team hopes to streamline later versions.Wetzstein's prototype glasses—dubbed autofocals—are intended to solve the main problem with today's progressive lenses: These traditional glasses require the wearer to align their head to focus properly. Imagine driving a car and looking in a side mirror to change lanes. With progressive lenses, there's little or no peripheral focus. The driver must switch from looking at the road ahead through the top of the glasses, then turn almost 90 degrees to see the nearby mirror through the lower part of the lens.This visual shift can also make it difficult to navigate the world. ""People wearing progressive lenses have a higher risk of falling and injuring themselves,"" said graduate student Robert Konrad, a co-author on a paper describing the autofocal glasses published June 28 in the journal Science Advances.The Stanford prototype works much like the lens of the eye, with fluid-filled lenses that bulge and thin as the field of vision changes. It also includes eye-tracking sensors that triangulate where a person is looking and determine the precise distance to the object of interest. The team did not invent these lenses or eye-trackers, but they did develop the software system that harnesses this eye-tracking data to keep the fluid-filled lenses in constant and perfect focus.Nitish Padmanaban, a graduate student and first author on the paper, said other teams had previously tried to apply autofocus lenses to presbyopia. But without guidance from the eye-tracking hardware and system software, those earlier efforts were no better than wearing traditional progressive lenses.To validate its approach, the Stanford team tested the prototype on 56 people with presbyopia. Test subjects said the autofocus lenses performed better and faster at reading and other tasks. Wearers also tended to prefer the autofocal glasses to the experience of progressive lenses—bulk and weight aside.If the approach sounds a bit like virtual reality, that isn't far off. Wetzstein's lab is at the forefront of vision systems for virtual and augmented reality. It was in the course of such work that the researchers became aware of the new autofocus lenses and eye-trackers and had the insight to combine these elements to create a potentially transformative product.The next step will be to downsize the technology. Wetzstein thinks it may take a few years to develop autofocal glasses that are lightweight, energy efficient and stylish. But he is convinced that autofocals are the future of vision correction.""This technology could affect billions of people's lives in a meaningful way that most techno-gadgets never will,"" he said.
                                                                                                                        "
Researchers step back to mannequin viral wave to explore depth,https://techxplore.com/news/2019-06-mannequin-viral-explore-depth.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/researcherss.gif,Computer Sciences,"Jun 29, 2019","Who said the viral craze called Mannequin Challenge (MC) is done and dusted? Not so. Researchers have turned to the Challenge that won attention in 2016 to serve their goal. They used the MC for training a neural network that can reconstruct depth information from the videos.
                                              ""Learning the  Depths of Moving People by Watching Frozen People"" is the name of their paper, now up on arXiv, authored by Zhengqi Li, Tali Dekel, Forrester Cole, Richard Tucker, Noah Snavely, Ce Liu and William Freeman. The paper was submitted in April this year.The Mannequin Challenge? Who can forget? This was a YouTube trend gone viral. Anthony Alford in InfoQ brought readers back to 2016, when an internet meme had people teamed in groups impersonate mannequins. They were ""frozen"" but a videographer would make moves around the scene taking a video from different angles. Alford wrote, because the camera is moving and the rest of the scene is static, parallax methods can easily reconstruct accurate depth maps of human figures in a variety of poses. As the authors stated, the videos involved freezing in diverse, natural poses, while a hand-held camera toured the scene.For training the neural network, the team converted 2,000 of the videos into 2-D images with high-resolution depth data. Alford said that out of the 2,000 YouTube MC videos,  a dataset  was produced of 4,690 sequences with a total of more than 170K valid image-depth pairs. The target of the learning system was the known depth map for the input image, computed from the MC videos. The DNN learned to take the input image, initial depth map, and human mask, and output a ""refined"" depth map where the depth values of humans were filled in.Christine Fisher, Engadget: ""To train the neural network, the researchers converted the clips into 2-D images, estimated the camera pose and created depth maps. The AI was then able to predict the depth of moving objects in videos with higher accuracy than previously possible."" Taking up the challenge was described by two of the paper's co-authors back in May in a Google blog. ""Because the entire scene is stationary (only the camera is moving), triangulation-based methods—like multi-view-stereo (MVS)—work, and we can get accurate depth maps for the entire scene including the people in it. We gathered approximately 2000 such videos, spanning a wide range of realistic scenes with people naturally posing in different group configurations."" Tali Dekel, research scientist and Forrester Cole, software engineer, machine perception, wrote more about the challenge they took on.""The human visual system has a remarkable ability to make sense of our 3-D world from its 2-D projection. Even in complex environments with multiple moving objects, people are able to maintain a feasible interpretation of the objects' geometry and depth ordering. The field of computer vision has long studied how to achieve similar capabilities by computationally reconstructing a scene's geometry from 2-D image data, but robust reconstruction remains difficult in many cases."" Why this matters: ""While there is a recent surge in using machine learning for depth prediction, this work is the first to tailor a learning-based approach to the case of simultaneous camera and human motion,"" they said in the May blog. ""In this work, we focus specifically on humans because they are an interesting target for augmented reality and 3-D video effects."" Talking about results, Karen Hao, MIT Technology Review, said the researchers converted 2,000 of the videos into 2-D images with high-resolution depth data and used them to train a neural network. It was then able to predict the depth of moving objects in a video at much higher accuracy than was possible with previous state-of-the-art methods.
                                                                                                                        "
A bite acquisition framework for robot-assisted feeding systems,https://techxplore.com/news/2019-06-acquisition-framework-robot-assisted.html,https://3c1703fe8d.site.internapcdn.net/newman/csz/news/175u/2019/abiteacquisi.jpg,Robotics,"Jun 28, 2019","According to a survey released by the U.S. Census Bureau, around 12.3 million Americans require assistance with activities of daily living (ADLs) or instrumental activities of daily living (IADLs), one of which is feeding. Robots could be of great help to people affected by severe disabilities, allowing them to eat meals and complete other daily tasks without reliance on constant assistance from other human beings.
                                              With this in mind, a team of researchers led by Prof. Siddhartha Srinivasa at the University of Washington's Personal Robotics Lab has been trying to develop a robot-assisted feeding system that can automatically pick up food from plates and feed it to human users. In a recent paper pre-published on arXiv, the researchers introduced a bite acquisition framework designed to calculate and attain reasonable ""bites"" of food from a plate or bowl.""As a lab, we are passionate about developing robots that can assist people in their day to day lives,"" Tapomayukh Bhattacharjee, one of the researchers who carried out the study, told TechXplore. ""Through this project, we want to develop robots that can feed people autonomously. To feed people a wide variety of food items, a robot needs to have the capability to acquire previously unseen food items. In this paper, we focus on the problem of bite acquisition of previously unseen food items.""A key challenge when developing robot-assisted feeding systems is ensuring that these robots can effectively pick up all the types of food they encounter. This can be difficult to achieve, as different food items have a variety of physical properties and thus require different acquisition strategies. Ideally, a robot-assisted feeding system should be able to pick up any food item on a plate, even if it has never encountered it before. To better understand what acquisition strategies work best for particular types of food, Bhattacharjee and his colleagues collected data from 2450 robot bite acquisition trials using 16 food items with varying properties. When they analyzed this data, they realized that items with similar physical properties exhibit similar acquisition success rates, which makes it easier to generalize an acquisition strategy to previously unseen items. Their analyses also offered insight into how other factors (e.g. the environment surrounding the food, fork pitch, fork angle, etc.) can affect a robot's success in picking up a bite of food from a plate. Based on these observations, the researchers developed a bite acquisition framework that uses two distinct neural networks in a hierarchical structure. The first network, called RetinaNet, analyzes full-plate images containing different types of food and then outputs bounding boxes around individual items. The second network, SPANet, uses these bounding boxes to calculate the success probability for different bite acquisition actions and the skewering axis for each food item. ""To output the success probability, SPANet also uses features related to the surrounding environment of a food item, as we found that the surrounding environment affects a robot's choice of actions as well as the success rate,"" Bhattacharjee explained. ""To encode the environment features, we developed an environment classifier that identifies items as being in one of three environments: isolated, near a plate edge or another food item, or on top of other food items.""The researchers applied their framework to a JACO robotic arm and evaluated its performance in a series of experiments on uncluttered and cluttered plates containing various food items. These tests yielded very promising results, with their method successfully generalizing skewering strategies across previously unseen food items. ""Our network, SPANet, could successfully generalize the actions to previously unseen food items with similar bite acquisition action distributions,"" Bhattacharjee said. ""Practically, this means that given a new food item that the robot hasn't seen before, our network should be able to infer how to acquire it successfully from a plate/bowl if the new food item can be acquired by similar actions.""In the future, the bite acquisition framework developed by Bhattacharjee and his colleagues could aid the development of more efficient robot-assisted feeding systems. Meanwhile, the researchers plan to extend their approach's bite acquisition actions, as this would allow robots powered by their framework to pick up an even wider variety of food, including items such as rice and mashed potato. ""We are also interested in exploring ways to acquire previously unseen food items which require very different actions for picking them up compared to what the robot has seen before,"" Bhattacharjee said.
                                                                                                                        "
